import { toFilter } from "./filter.js";
import { compareLogLevel } from "./level.js";
import { defaultConsoleFormatter, defaultTextFormatter } from "./formatter.js";

//#region src/sink.ts
/**
* Turns a sink into a filtered sink.  The returned sink only logs records that
* pass the filter.
*
* @example Filter a console sink to only log records with the info level
* ```typescript
* const sink = withFilter(getConsoleSink(), "info");
* ```
*
* @param sink A sink to be filtered.
* @param filter A filter to apply to the sink.  It can be either a filter
*               function or a {@link LogLevel} string.
* @returns A sink that only logs records that pass the filter.
*/
function withFilter(sink, filter) {
	const filterFunc = toFilter(filter);
	return (record) => {
		if (filterFunc(record)) sink(record);
	};
}
/**
* A factory that returns a sink that writes to a {@link WritableStream}.
*
* Note that the `stream` is of Web Streams API, which is different from
* Node.js streams.  You can convert a Node.js stream to a Web Streams API
* stream using [`stream.Writable.toWeb()`] method.
*
* [`stream.Writable.toWeb()`]: https://nodejs.org/api/stream.html#streamwritabletowebstreamwritable
*
* @example Sink to the standard error in Deno
* ```typescript
* const stderrSink = getStreamSink(Deno.stderr.writable);
* ```
*
* @example Sink to the standard error in Node.js
* ```typescript
* import stream from "node:stream";
* const stderrSink = getStreamSink(stream.Writable.toWeb(process.stderr));
* ```
*
* @param stream The stream to write to.
* @param options The options for the sink.
* @returns A sink that writes to the stream.
*/
function getStreamSink(stream, options = {}) {
	const formatter = options.formatter ?? defaultTextFormatter;
	const encoder = options.encoder ?? new TextEncoder();
	const writer = stream.getWriter();
	if (!options.nonBlocking) {
		let lastPromise = Promise.resolve();
		const sink = (record) => {
			const bytes = encoder.encode(formatter(record));
			lastPromise = lastPromise.then(() => writer.ready).then(() => writer.write(bytes));
		};
		sink[Symbol.asyncDispose] = async () => {
			await lastPromise;
			await writer.close();
		};
		return sink;
	}
	const nonBlockingConfig = options.nonBlocking === true ? {} : options.nonBlocking;
	const bufferSize = nonBlockingConfig.bufferSize ?? 100;
	const flushInterval = nonBlockingConfig.flushInterval ?? 100;
	const buffer = [];
	let flushTimer = null;
	let disposed = false;
	let activeFlush = null;
	const maxBufferSize = bufferSize * 2;
	async function flush() {
		if (buffer.length === 0) return;
		const records = buffer.splice(0);
		for (const record of records) try {
			const bytes = encoder.encode(formatter(record));
			await writer.ready;
			await writer.write(bytes);
		} catch {}
	}
	function scheduleFlush() {
		if (activeFlush) return;
		activeFlush = flush().finally(() => {
			activeFlush = null;
		});
	}
	function startFlushTimer() {
		if (flushTimer !== null || disposed) return;
		flushTimer = setInterval(() => {
			scheduleFlush();
		}, flushInterval);
	}
	const nonBlockingSink = (record) => {
		if (disposed) return;
		if (buffer.length >= maxBufferSize) buffer.shift();
		buffer.push(record);
		if (buffer.length >= bufferSize) scheduleFlush();
		else if (flushTimer === null) startFlushTimer();
	};
	nonBlockingSink[Symbol.asyncDispose] = async () => {
		disposed = true;
		if (flushTimer !== null) {
			clearInterval(flushTimer);
			flushTimer = null;
		}
		await flush();
		try {
			await writer.close();
		} catch {}
	};
	return nonBlockingSink;
}
/**
* A console sink factory that returns a sink that logs to the console.
*
* @param options The options for the sink.
* @returns A sink that logs to the console. If `nonBlocking` is enabled,
*          returns a sink that also implements {@link Disposable}.
*/
function getConsoleSink(options = {}) {
	const formatter = options.formatter ?? defaultConsoleFormatter;
	const levelMap = {
		trace: "debug",
		debug: "debug",
		info: "info",
		warning: "warn",
		error: "error",
		fatal: "error",
		...options.levelMap ?? {}
	};
	const console = options.console ?? globalThis.console;
	const baseSink = (record) => {
		const args = formatter(record);
		const method = levelMap[record.level];
		if (method === void 0) throw new TypeError(`Invalid log level: ${record.level}.`);
		if (typeof args === "string") {
			const msg = args.replace(/\r?\n$/, "");
			console[method](msg);
		} else console[method](...args);
	};
	if (!options.nonBlocking) return baseSink;
	const nonBlockingConfig = options.nonBlocking === true ? {} : options.nonBlocking;
	const bufferSize = nonBlockingConfig.bufferSize ?? 100;
	const flushInterval = nonBlockingConfig.flushInterval ?? 100;
	const buffer = [];
	let flushTimer = null;
	let disposed = false;
	let flushScheduled = false;
	const maxBufferSize = bufferSize * 2;
	function flush() {
		if (buffer.length === 0) return;
		const records = buffer.splice(0);
		for (const record of records) try {
			baseSink(record);
		} catch {}
	}
	function scheduleFlush() {
		if (flushScheduled) return;
		flushScheduled = true;
		setTimeout(() => {
			flushScheduled = false;
			flush();
		}, 0);
	}
	function startFlushTimer() {
		if (flushTimer !== null || disposed) return;
		flushTimer = setInterval(() => {
			flush();
		}, flushInterval);
	}
	const nonBlockingSink = (record) => {
		if (disposed) return;
		if (buffer.length >= maxBufferSize) buffer.shift();
		buffer.push(record);
		if (buffer.length >= bufferSize) scheduleFlush();
		else if (flushTimer === null) startFlushTimer();
	};
	nonBlockingSink[Symbol.dispose] = () => {
		disposed = true;
		if (flushTimer !== null) {
			clearInterval(flushTimer);
			flushTimer = null;
		}
		flush();
	};
	return nonBlockingSink;
}
/**
* Converts an async sink into a regular sink with proper async handling.
* The returned sink chains async operations to ensure proper ordering and
* implements AsyncDisposable to wait for all pending operations on disposal.
*
* @example Create a sink that asynchronously posts to a webhook
* ```typescript
* const asyncSink: AsyncSink = async (record) => {
*   await fetch("https://example.com/logs", {
*     method: "POST",
*     body: JSON.stringify(record),
*   });
* };
* const sink = fromAsyncSink(asyncSink);
* ```
*
* @param asyncSink The async sink function to convert.
* @returns A sink that properly handles async operations and disposal.
* @since 1.0.0
*/
function fromAsyncSink(asyncSink) {
	let lastPromise = Promise.resolve();
	const sink = (record) => {
		lastPromise = lastPromise.then(() => asyncSink(record)).catch(() => {});
	};
	sink[Symbol.asyncDispose] = async () => {
		await lastPromise;
	};
	return sink;
}
/**
* Creates a sink that buffers log records until a trigger level is reached.
* This pattern, known as "fingers crossed" logging, keeps detailed debug logs
* in memory and only outputs them when an error or other significant event occurs.
*
* @example Basic usage with default settings
* ```typescript
* const sink = fingersCrossed(getConsoleSink());
* // Debug and info logs are buffered
* // When an error occurs, all buffered logs + the error are output
* ```
*
* @example Custom trigger level and buffer size
* ```typescript
* const sink = fingersCrossed(getConsoleSink(), {
*   triggerLevel: "warning",  // Trigger on warning or higher
*   maxBufferSize: 500        // Keep last 500 records
* });
* ```
*
* @example Category isolation
* ```typescript
* const sink = fingersCrossed(getConsoleSink(), {
*   isolateByCategory: "descendant"  // Separate buffers per category
* });
* // Error in ["app"] triggers flush of ["app"] and ["app", "module"] buffers
* // But not ["other"] buffer
* ```
*
* @param sink The sink to wrap. Buffered records are sent to this sink when
*             triggered.
* @param options Configuration options for the fingers crossed behavior.
* @returns A sink that buffers records until the trigger level is reached.
* @since 1.1.0
*/
function fingersCrossed(sink, options = {}) {
	const triggerLevel = options.triggerLevel ?? "error";
	const maxBufferSize = Math.max(0, options.maxBufferSize ?? 1e3);
	const isolateByCategory = options.isolateByCategory;
	const isolateByContext = options.isolateByContext;
	const bufferTtlMs = isolateByContext?.bufferTtlMs;
	const cleanupIntervalMs = isolateByContext?.cleanupIntervalMs ?? 3e4;
	const maxContexts = isolateByContext?.maxContexts;
	const hasTtl = bufferTtlMs != null && bufferTtlMs > 0;
	const hasLru = maxContexts != null && maxContexts > 0;
	try {
		compareLogLevel("trace", triggerLevel);
	} catch (error) {
		throw new TypeError(`Invalid triggerLevel: ${JSON.stringify(triggerLevel)}. ${error instanceof Error ? error.message : String(error)}`);
	}
	function isDescendant(parent, child) {
		if (parent.length === 0 || child.length === 0) return false;
		if (parent.length > child.length) return false;
		return parent.every((p, i) => p === child[i]);
	}
	function isAncestor(child, parent) {
		if (child.length === 0 || parent.length === 0) return false;
		if (child.length < parent.length) return false;
		return parent.every((p, i) => p === child[i]);
	}
	let shouldFlushBuffer = null;
	if (isolateByCategory) if (typeof isolateByCategory === "function") shouldFlushBuffer = isolateByCategory;
	else switch (isolateByCategory) {
		case "descendant":
			shouldFlushBuffer = (trigger, buffered) => isDescendant(trigger, buffered);
			break;
		case "ancestor":
			shouldFlushBuffer = (trigger, buffered) => isAncestor(trigger, buffered);
			break;
		case "both":
			shouldFlushBuffer = (trigger, buffered) => isDescendant(trigger, buffered) || isAncestor(trigger, buffered);
			break;
	}
	function getCategoryKey(category) {
		return JSON.stringify(category);
	}
	function parseCategoryKey(key) {
		return JSON.parse(key);
	}
	function getContextKey(properties) {
		if (!isolateByContext || isolateByContext.keys.length === 0) return "";
		const contextValues = {};
		for (const key of isolateByContext.keys) if (key in properties) contextValues[key] = properties[key];
		return JSON.stringify(contextValues);
	}
	function getBufferKey(category, properties) {
		const categoryKey = getCategoryKey(category);
		if (!isolateByContext) return categoryKey;
		const contextKey = getContextKey(properties);
		return `${categoryKey}:${contextKey}`;
	}
	function parseBufferKey(key) {
		if (!isolateByContext) return {
			category: parseCategoryKey(key),
			context: ""
		};
		const separatorIndex = key.indexOf("]:");
		if (separatorIndex === -1) return {
			category: parseCategoryKey(key),
			context: ""
		};
		const categoryPart = key.substring(0, separatorIndex + 1);
		const contextPart = key.substring(separatorIndex + 2);
		return {
			category: parseCategoryKey(categoryPart),
			context: contextPart
		};
	}
	function cleanupExpiredBuffers(buffers) {
		if (!hasTtl) return;
		const now = Date.now();
		const expiredKeys = [];
		for (const [key, metadata] of buffers) {
			if (metadata.buffer.length === 0) continue;
			const lastRecordTimestamp = metadata.buffer[metadata.buffer.length - 1].timestamp;
			if (now - lastRecordTimestamp > bufferTtlMs) expiredKeys.push(key);
		}
		for (const key of expiredKeys) buffers.delete(key);
	}
	function evictLruBuffers(buffers, numToEvict) {
		if (!hasLru) return;
		const toEvict = numToEvict ?? Math.max(0, buffers.size - maxContexts);
		if (toEvict <= 0) return;
		const sortedEntries = Array.from(buffers.entries()).sort(([, a], [, b]) => a.lastAccess - b.lastAccess);
		for (let i = 0; i < toEvict; i++) {
			const [key] = sortedEntries[i];
			buffers.delete(key);
		}
	}
	if (!isolateByCategory && !isolateByContext) {
		const buffer = [];
		let triggered = false;
		return (record) => {
			if (triggered) {
				sink(record);
				return;
			}
			if (compareLogLevel(record.level, triggerLevel) >= 0) {
				triggered = true;
				for (const bufferedRecord of buffer) sink(bufferedRecord);
				buffer.length = 0;
				sink(record);
			} else {
				buffer.push(record);
				while (buffer.length > maxBufferSize) buffer.shift();
			}
		};
	} else {
		const buffers = /* @__PURE__ */ new Map();
		const triggered = /* @__PURE__ */ new Set();
		let cleanupTimer = null;
		if (hasTtl) cleanupTimer = setInterval(() => {
			cleanupExpiredBuffers(buffers);
		}, cleanupIntervalMs);
		const fingersCrossedSink = (record) => {
			const bufferKey = getBufferKey(record.category, record.properties);
			if (triggered.has(bufferKey)) {
				sink(record);
				return;
			}
			if (compareLogLevel(record.level, triggerLevel) >= 0) {
				const keysToFlush = /* @__PURE__ */ new Set();
				for (const [bufferedKey] of buffers) if (bufferedKey === bufferKey) keysToFlush.add(bufferedKey);
				else {
					const { category: bufferedCategory, context: bufferedContext } = parseBufferKey(bufferedKey);
					const { context: triggerContext } = parseBufferKey(bufferKey);
					let contextMatches = true;
					if (isolateByContext) contextMatches = bufferedContext === triggerContext;
					let categoryMatches = false;
					if (!isolateByCategory) categoryMatches = contextMatches;
					else if (shouldFlushBuffer) try {
						categoryMatches = shouldFlushBuffer(record.category, bufferedCategory);
					} catch {}
					else categoryMatches = getCategoryKey(record.category) === getCategoryKey(bufferedCategory);
					if (contextMatches && categoryMatches) keysToFlush.add(bufferedKey);
				}
				const allRecordsToFlush = [];
				for (const key of keysToFlush) {
					const metadata = buffers.get(key);
					if (metadata) {
						allRecordsToFlush.push(...metadata.buffer);
						buffers.delete(key);
						triggered.add(key);
					}
				}
				allRecordsToFlush.sort((a, b) => a.timestamp - b.timestamp);
				for (const bufferedRecord of allRecordsToFlush) sink(bufferedRecord);
				triggered.add(bufferKey);
				sink(record);
			} else {
				const now = Date.now();
				let metadata = buffers.get(bufferKey);
				if (!metadata) {
					if (hasLru && buffers.size >= maxContexts) {
						const numToEvict = buffers.size - maxContexts + 1;
						evictLruBuffers(buffers, numToEvict);
					}
					metadata = {
						buffer: [],
						lastAccess: now
					};
					buffers.set(bufferKey, metadata);
				} else metadata.lastAccess = now;
				metadata.buffer.push(record);
				while (metadata.buffer.length > maxBufferSize) metadata.buffer.shift();
			}
		};
		if (cleanupTimer !== null) fingersCrossedSink[Symbol.dispose] = () => {
			if (cleanupTimer !== null) {
				clearInterval(cleanupTimer);
				cleanupTimer = null;
			}
		};
		return fingersCrossedSink;
	}
}

//#endregion
export { fingersCrossed, fromAsyncSink, getConsoleSink, getStreamSink, withFilter };
//# sourceMappingURL=sink.js.map